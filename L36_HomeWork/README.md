
# üî¢ MNIST Handwritten Digit Classification

A comprehensive deep learning project for classifying handwritten digits using Keras/TensorFlow. This project demonstrates the full pipeline: loading data, building and training neural networks, evaluating results, and visualizing outputs. The notebook and code are designed for both educational and practical use.

---

## üìÅ Repository Structure

```
L36_HomeWork/
‚îú‚îÄ‚îÄ main.py                                # Main entry point
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                        # Package init
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py                     # Data loading & preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ model.py                           # Neural network architecture
‚îÇ   ‚îú‚îÄ‚îÄ training.py                        # Training & visualization
‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py                      # Prediction & error analysis
‚îú‚îÄ‚îÄ output/                                # Generated visualizations
‚îÇ   ‚îú‚îÄ‚îÄ mnist_samples.png                  # Sample digit images
‚îÇ   ‚îú‚îÄ‚îÄ training_history.png               # Loss/accuracy curves
‚îÇ   ‚îú‚îÄ‚îÄ prediction.png                     # Single prediction example
‚îÇ   ‚îú‚îÄ‚îÄ misclassified.png                  # Error analysis grid
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png               # 10x10 confusion matrix
‚îú‚îÄ‚îÄ MNIST_Classification_Notebook.ipynb    # Jupyter Notebook (for Google Colab)
‚îú‚îÄ‚îÄ README.md                              # This documentation
‚îî‚îÄ‚îÄ .gitignore                             # Git ignore rules
```

### Module Overview

| File                | ~Lines | Purpose                                 |
|---------------------|--------|-----------------------------------------|
| main.py             | ~80    | Orchestrates the complete pipeline      |
| data_loader.py      | ~75    | Load MNIST, visualize samples, preprocess |
| model.py            | ~75    | Build & compile neural networks         |
| training.py         | ~85    | Train models, plot history, compare     |
| evaluation.py       | ~95    | Predictions, error analysis, confusion matrix |

All Python files are under 150 lines ‚úì

---

## üöÄ How to Run

### Option 1: Local Execution (Recommended)

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install tensorflow numpy matplotlib seaborn scikit-learn

# Run the complete pipeline
python main.py
# Output: All visualizations are saved to the `output/` folder.
```

### Option 2: Google Colab
1. Open [Google Colab](https://colab.research.google.com/)
2. Upload `MNIST_Classification_Notebook.ipynb`
3. Click Runtime ‚Üí Run all

> Tip: Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU

---

## üîÑ Data Flow Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         DATA FLOW DIAGRAM                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

	‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
	‚îÇ  MNIST Data  ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ  Preprocessing   ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ  Neural Network  ‚îÇ
	‚îÇ  (Raw Input) ‚îÇ     ‚îÇ  (data_loader)   ‚îÇ     ‚îÇ    (model.py)    ‚îÇ
	‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
				‚îÇ                      ‚îÇ                        ‚îÇ
				‚ñº                      ‚ñº                        ‚ñº
	60,000 train images    ‚Ä¢ Normalize (0-1)      ‚Ä¢ 784 input neurons
	10,000 test images     ‚Ä¢ One-hot encode       ‚Ä¢ 3 hidden layers
	28√ó28 grayscale        ‚Ä¢ Flatten to 784D      ‚Ä¢ 10 output neurons
																												‚îÇ
												 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
												 ‚ñº
				 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
				 ‚îÇ                  TRAINING (training.py)           ‚îÇ
				 ‚îÇ  ‚Ä¢ Epochs: 20  ‚Ä¢ Batch: 128  ‚Ä¢ Val Split: 10%     ‚îÇ
				 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
												 ‚îÇ
												 ‚ñº
				 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
				 ‚îÇ              EVALUATION (evaluation.py)           ‚îÇ
				 ‚îÇ  ‚Ä¢ Predictions  ‚Ä¢ Error Analysis  ‚Ä¢ Confusion Mx  ‚îÇ
				 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Output Visualizations

### 1. MNIST Sample Images
Random samples from the training dataset showing handwriting variability.

![MNIST Samples](https://github.com/alienspirit7/L36_HomeWork/raw/main/output/mnist_samples.png)

### 2. Training History
Loss and accuracy curves showing model learning over 20 epochs.

![Training History](https://github.com/alienspirit7/L36_HomeWork/raw/main/output/training_history.png)

### 3. Single Prediction Example
Model prediction on a specific digit with confidence scores.

![Prediction](https://github.com/alienspirit7/L36_HomeWork/raw/main/output/prediction.png)

### 4. Misclassified Images
Grid of incorrectly classified samples (Red = Predicted, Blue = Actual).

![Misclassified](https://github.com/alienspirit7/L36_HomeWork/raw/main/output/misclassified.png)

### 5. Confusion Matrix
10√ó10 matrix showing prediction patterns. Diagonal = correct predictions.

![Confusion Matrix](https://github.com/alienspirit7/L36_HomeWork/raw/main/output/confusion_matrix.png)

---

## üìñ Step-by-Step Explanation

### Section 1: Data Loading & Exploration
Module: `src/data_loader.py` ‚Üí `load_mnist()`, `visualize_samples()`

‚Ä¢ Loads the MNIST dataset (built into Keras)
‚Ä¢ Displays dataset statistics
‚Ä¢ Visualizes 16 random samples in a 4√ó4 grid

### Section 2: Preprocessing
Module: `src/data_loader.py` ‚Üí `preprocess_data()`

| Step           | From      | To        | Purpose                  |
|----------------|-----------|-----------|--------------------------|
| Normalization  | [0-255]   | [0-1]     | Faster convergence       |
| One-Hot Encoding | int (0-9) | 10D vector | For crossentropy loss    |
| Flattening     | 28√ó28     | 784D      | Dense layer input        |

### Section 3: Model Architecture
Module: `src/model.py` ‚Üí `build_model()`

```
Input(784) ‚Üí Dense(512,ReLU) ‚Üí Dense(256,ReLU) ‚Üí Dense(128,ReLU) ‚Üí Output(10,Softmax)
```

‚Ä¢ Dropout (0.2): Prevents overfitting
‚Ä¢ ReLU: Efficient, avoids vanishing gradients
‚Ä¢ Softmax: Outputs probability distribution

### Section 4: Compilation
Module: `src/model.py` ‚Üí `compile_model()`

| Step     | Setting                  | Purpose                      |
|----------|--------------------------|------------------------------|
| Loss     | Categorical Crossentropy | Multi-class classification   |
| Optimizer| Adam (lr=0.001)          | Adaptive learning rate       |
| Metric   | Accuracy                 | Intuitive performance measure|

### Section 5: Training & Monitoring
Module: `src/training.py` ‚Üí `train_model()`, `plot_training_history()`

‚Ä¢ Epochs: 20 | Batch: 128 | Validation: 10%
‚Ä¢ Generates loss and accuracy curves
‚Ä¢ Detects overfitting via validation gap

### Section 6: Prediction
Module: `src/evaluation.py` ‚Üí `predict_single()`

‚Ä¢ Selects a specific digit (e.g., '7') from test set
‚Ä¢ Shows probability distribution for all classes
‚Ä¢ Visualizes image + bar chart

### Section 7: Error Analysis
Module: `src/evaluation.py` ‚Üí `analyze_errors()`, `plot_confusion_matrix()`

‚Ä¢ Identifies all misclassified images
‚Ä¢ Displays 25 error examples
‚Ä¢ Generates 10√ó10 confusion matrix
‚Ä¢ Reports top confused digit pairs

### Section 8: Hyperparameter Optimization
Module: `src/model.py` ‚Üí `build_improved_model()`

| Param         | Baseline | Improved |
|---------------|----------|----------|
| Learning Rate | 0.001    | 0.0005   |
| Hidden Layers | 3        | 4        |
| Dropout       | 0.2      | 0.3      |
| Epochs        | 20       | 25       |

---

## üéØ Results

| Model    | Accuracy | Loss   |
|----------|----------|--------|
| Original | 98.29%   | 0.0771 |
| Improved | 98.38%   | 0.0731 |

Improvement: +0.09% accuracy

---

## üîß Troubleshooting

- **Slow training?** Use a subset of data (edit `main.py`):
	```python
	X_train_p = X_train_p[:10000]
	y_train_p = y_train_p[:10000]
	```
- **Memory issues?** Reduce batch size in `train_model()`:
	```python
	train_model(model, X_train_p, y_train_p, batch_size=32)
	```
- **TensorFlow not found?** Install with `pip install tensorflow`.
- **Plots not saving?** Ensure `output/` exists and is writable.
- **Low accuracy?** Check preprocessing, model structure, and training parameters.
- **Colab GPU:** In Colab, select `Runtime > Change runtime type > GPU` for faster training.

---

## üìù License

Educational project for learning purposes.

---

## Additional Links
- [Project Repository](https://github.com/alienspirit7/L36_HomeWork)
- [Issues](https://github.com/alienspirit7/L36_HomeWork/issues)
- [Pull requests](https://github.com/alienspirit7/L36_HomeWork/pulls)
- [Google Colab Notebook](https://colab.research.google.com/)